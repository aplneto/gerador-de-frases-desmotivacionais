{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "if866_-_criatividade_computacional.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aplneto/gerador-de-frases-desmotivacionais/blob/main/if866_-_criatividade_computacional.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install transformers==4.18.0 --quiet"
      ],
      "metadata": {
        "id": "6Ef46T9sJP6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer, GPT2Model, pipeline"
      ],
      "metadata": {
        "id": "5jma38vpMDjb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GPT2_MODEL_NAME = 'pierreguillou/gpt2-small-portuguese'\n",
        "GPT2_MODEL_URL = 'https://huggingface.co/pierreguillou/gpt2-small-portuguese'\n",
        "gpt2_tokenizer = GPT2Tokenizer.from_pretrained(\n",
        "    GPT2_MODEL_NAME,\n",
        "    bos_token='<|startoftext|>',\n",
        "    eos_token='<|endoftext|>',\n",
        "    pad_token='<|pad|>',\n",
        "    sep_token='<|sep|>'\n",
        ")\n",
        "gpt2_model = GPT2Model.from_pretrained(GPT2_MODEL_NAME, return_dict=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvgRvc5iLq1C",
        "outputId": "f7ce741d-c65f-4cca-cf79-02eb8c0457b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Some weights of the model checkpoint at pierreguillou/gpt2-small-portuguese were not used when initializing GPT2Model: ['lm_head.weight']\n",
            "- This IS expected if you are initializing GPT2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing GPT2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import set_seed"
      ],
      "metadata": {
        "id": "btO4y6f85rEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = pipeline('text-generation', model=gpt2_model.name_or_path)\n",
        "set_seed(42)\n",
        "generator(\n",
        "    \"Quem era Jim Henson? Jim Henson era um\",\n",
        "    max_length=30,\n",
        "    num_return_sequences=5\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iyFjaT45s3J",
        "outputId": "a3026ccf-8827-44c6-b56d-3d956972656d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'Quem era Jim Henson? Jim Henson era um \"patrão\", mas seu passado e personalidade eram claramente mais forte que seu irmão, embora ele'},\n",
              " {'generated_text': 'Quem era Jim Henson? Jim Henson era um membro da família DuPont (que era de ascendência norte-americana) e Jim Jr. ('},\n",
              " {'generated_text': 'Quem era Jim Henson? Jim Henson era um engenheiro de máquinas e eletricidade. Jim Henson começou seus estudos para estudar eletromagnetismo. \\n\\n'},\n",
              " {'generated_text': 'Quem era Jim Henson? Jim Henson era um bom amigo de Frank Lloyd Wright e seu editor de \"The New Yorker\". \"Jim H'},\n",
              " {'generated_text': 'Quem era Jim Henson? Jim Henson era um funcionário do governo nos EUA, e o Sr. Henson era um dos donos da empresa.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(4)\n",
        "generator('Nada é tão ruim que não', num_return_sequences = 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pts63y-A7pvs",
        "outputId": "cac4b99b-ffd8-4afa-c694-0cfd35d6f51b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'Nada é tão ruim que não podemos dar isso e nem nos ajudar a melhorar nossas vidas como um todo, quando se tratamos da gente, de crianças, de adolescentes e de famílias\".\\nJosé Manuel Soares, Presidente da Fundação Fernando Collor, (São'},\n",
              " {'generated_text': 'Nada é tão ruim que não é mais de tudo para eles, mas sim uma tarefa e um projeto. \"Um dia você conhece alguém que está a ponto de alguém que vai querer algo e que por isso você está ansioso para algo que o outro não'},\n",
              " {'generated_text': 'Nada é tão ruim que não consegue se entender em que circunstâncias. \"\\n\\nEm um dia que começa bem como tudo, ele está sempre com emoções que o levou a acreditar que ele está no caminho a chegar a ser realmente grande demais. Mas ele'},\n",
              " {'generated_text': 'Nada é tão ruim que não seria um dos piores momentos da vida. Nós ficamos em uma fazenda mexicana e todos os outros seres faltaram... É um grande desastre\", afirma Regina para o jornal americano \"The New York Times\".\\nA novela foi'},\n",
              " {'generated_text': 'Nada é tão ruim que não quer que você fale\".\\n\\n\"E agora… Você sabe que não vale pena de voltar para sua cidadezinha por ser uma mulher de negócios. \" - Kyra, do \"The O.V. Club\"'}]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy --quiet"
      ],
      "metadata": {
        "id": "xlGEk7c6tHrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !python -m spacy download pt_core_news_sm --quiet\n",
        "# !python -m spacy download pt_core_news_md --quiet\n",
        "# !python -m spacy download pt_core_news_lg --quiet"
      ],
      "metadata": {
        "id": "p-QIsa_iQJlV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install odfpy --quiet"
      ],
      "metadata": {
        "id": "FLxXHbN4U1tX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas"
      ],
      "metadata": {
        "id": "baVruRgeSsRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe = pandas.read_excel('frasesDesmotivacionais.ods', engine='odf')"
      ],
      "metadata": {
        "id": "Y_CPrpekUMb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe.reset_index(drop=True, inplace=True)\n",
        "dataframe.drop(labels='ID', inplace=True, axis=1)\n",
        "dataframe.rename(columns = {'Frases': 'completion'}, inplace=True)\n",
        "dataframe.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "8ajGUnS7U9jz",
        "outputId": "c47f9d34-980c-4acf-91df-2353ccd0cff9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          completion\n",
              "0       Nenhum obstáculo é grande para quem desiste.\n",
              "1    Nada é tão horrível que não possa piorar muito!\n",
              "2                     É só uma fase logo vai piorar.\n",
              "3  Você não pode mudar o seu passado. Mas pode es...\n",
              "4                         Sem lutas não há derrotas."
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>completion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Nenhum obstáculo é grande para quem desiste.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Nada é tão horrível que não possa piorar muito!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>É só uma fase logo vai piorar.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Você não pode mudar o seu passado. Mas pode es...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sem lutas não há derrotas.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import spacy\n",
        "import random\n",
        "from torch.utils.data import Dataset"
      ],
      "metadata": {
        "id": "94SKwo0gaQt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "maxl = 50"
      ],
      "metadata": {
        "id": "kXBzHCQAag9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SPECIAL_TOKENS = gpt2_tokenizer.special_tokens_map"
      ],
      "metadata": {
        "id": "kIn3lf9GuP0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SentenceDataset(Dataset):\n",
        "  def __init__(self, sentence_list, tokenizer, gpt2_type, max_length=maxl):\n",
        "    self.tokenizer = tokenizer\n",
        "    self.input_ids = []\n",
        "    self.attn_masks = []\n",
        "    self.nlp = spacy.load(\"pt_core_news_lg\")\n",
        "    self.sentences = sentence_list\n",
        "\n",
        "    for inputs, masks in self.get_inputs_and_masks():\n",
        "      self.input_ids.append(inputs)\n",
        "      self.attn_masks.append(masks)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.input_ids)\n",
        "  \n",
        "  def get_inputs_and_masks(self):\n",
        "    for sentence in self.sentences:\n",
        "      input = (\n",
        "          SPECIAL_TOKENS['bos_token'] +\n",
        "          ','.join(self.get_sentence_keywords(sentence)) +\n",
        "          SPECIAL_TOKENS['sep_token'] +\n",
        "          sentence +\n",
        "          SPECIAL_TOKENS['eos_token']\n",
        "      )\n",
        "      encoding_dict = self.tokenizer(\n",
        "          input,\n",
        "          truncation=True,\n",
        "          max_length=maxl,\n",
        "          padding='max_length'\n",
        "      )\n",
        "      inputs = torch.tensor(encoding_dict['input_ids'])\n",
        "      masks = torch.tensor(encoding_dict['attention_mask'])\n",
        "      yield inputs, masks\n",
        "  \n",
        "  def reset_dataset(self):\n",
        "    for i, inputs, masks in enumerate(self.get_inputs_and_masks()):\n",
        "      self.input_ids[i] = inputs\n",
        "      self.attn_masks[i] = maks\n",
        "  \n",
        "  def __getitem__(self, i):\n",
        "    return self.input_ids[i], self.attn_masks[i]\n",
        "  \n",
        "  def get_sentence_keywords(self, text):\n",
        "    doc = self.nlp(text)\n",
        "    stopwords = self.nlp.Defaults.stop_words\n",
        "    keywords = [token.lemma_ for token in doc if token.lemma_ not in stopwords]\n",
        "    for word in keywords:\n",
        "      if word in ',.?!:;-/@':\n",
        "        keywords.remove(word)\n",
        "    random.shuffle(keywords)\n",
        "    return keywords"
      ],
      "metadata": {
        "id": "i2yfPqauaVH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = SentenceDataset(\n",
        "    dataframe['completion'], gpt2_tokenizer, gpt2_model.name_or_path\n",
        ")\n",
        "dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWLJXIpWew8c",
        "outputId": "99d9ce05-cd45-419b-f87c-73eafcb21ea8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([50257,  1201,  4645,    12, 34955,  7211,    12,    78, 32664, 50258,\n",
              "         44897, 26234,   372,   867,   341,  2033, 41736,    14,     0, 50259,\n",
              "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
              "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
              "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259]),\n",
              " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0]))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler"
      ],
      "metadata": {
        "id": "CF7x4VdwfMg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batchsize = 10\n",
        "\n",
        "dataloader = DataLoader(\n",
        "    dataset,\n",
        "    sampler = RandomSampler(dataset),\n",
        "    batch_size = batchsize\n",
        ")"
      ],
      "metadata": {
        "id": "tkNH_u7ogjeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelWithLMHead, GPT2Config"
      ],
      "metadata": {
        "id": "mZWU6iAIgxtg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "configuration = GPT2Config.from_pretrained(\n",
        "    GPT2_MODEL_NAME, output_hidden_states=False\n",
        ")\n",
        "model = AutoModelWithLMHead.from_pretrained(\n",
        "    GPT2_MODEL_NAME, config=configuration\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbDWpWyGhUYM",
        "outputId": "9422a10e-5426-4b66-96b5-1ddc5ed5a851"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\aplne\\anaconda3\\envs\\cuda-torch\\lib\\site-packages\\transformers\\models\\auto\\modeling_auto.py:907: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.resize_token_embeddings(len(gpt2_tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAr2ZcxmhlBg",
        "outputId": "ac1dbe1c-8c07-4787-8d09-9ce89036b714"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(50260, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda')\n",
        "  model.cuda()\n",
        "else:\n",
        "  device = torch.device('cpu')\n",
        "  model.cpu()"
      ],
      "metadata": {
        "id": "qogdQrtvhwRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy"
      ],
      "metadata": {
        "id": "iGqrUF3hiZdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "numpy.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "if torch.cuda.is_available():\n",
        "  torch.cuda.manual_seed_all(seed_val)"
      ],
      "metadata": {
        "id": "Mv_6ovoTifPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 100\n",
        "warmup_steps = 1e2\n",
        "sample_every = 10"
      ],
      "metadata": {
        "id": "N0kPeCTOi1G2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, eps=1e-8)"
      ],
      "metadata": {
        "id": "HHk8YQcWi-hO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_linear_schedule_with_warmup"
      ],
      "metadata": {
        "id": "sG8K7WQZjA22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_steps = len(dataset) * epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer, num_warmup_steps = warmup_steps, num_training_steps = total_steps\n",
        ")"
      ],
      "metadata": {
        "id": "ut8GfdU6jRQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "rTkY9kcXjfw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2_tokenizer.decode(model.generate()[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waJTr-AKktO0",
        "outputId": "dca44106-e7cf-4736-b6fb-5389e43c61cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Olivais, em <|startoftext|> bi, no <|startoftext|> bi, no <|startoftext|> bi, no <|startoftext|> bi, no <|startoftext|>'"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss_hist = []\n",
        "for epoch_i in range(epochs):\n",
        "  total_train_loss = 0\n",
        "  model.train()\n",
        "  print(f'Epoch: {epoch_i+1}/{epochs}')\n",
        "  for step, batch in enumerate(dataloader):\n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_labels = batch[0].to(device)\n",
        "    b_masks = batch[1].to(device)\n",
        "\n",
        "    model.zero_grad()\n",
        "    outputs = model(\n",
        "        b_input_ids, labels=b_labels,\n",
        "        attention_mask = b_masks,\n",
        "        token_type_ids=None\n",
        "    )\n",
        "\n",
        "    loss = outputs[0]\n",
        "\n",
        "    batch_loss = loss.item()\n",
        "    total_train_loss += batch_loss\n",
        "\n",
        "    if (((step+1) % sample_every) == 0):\n",
        "      model.eval()\n",
        "      prompt = SPECIAL_TOKENS['bos_token'] + SPECIAL_TOKENS['sep_token']\n",
        "      p = torch.tensor(gpt2_tokenizer.encode(prompt)).unsqueeze(0)\n",
        "      p = p.to(device)\n",
        "      sample_outputs = model.generate(\n",
        "          p,\n",
        "          do_sample=True,\n",
        "          max_length = maxl,\n",
        "          num_return_sequences=1\n",
        "      )\n",
        "      sample_seq = sample_outputs[0]\n",
        "      out_seq = gpt2_tokenizer.decode(sample_seq, skip_special_tokens=True)\n",
        "      print(f'Example output: [{out_seq}]')\n",
        "\n",
        "      model.train()\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "  \n",
        "  avg_train_loss = total_train_loss / len(dataloader)\n",
        "  print(f'Average Training Loss: {avg_train_loss}.')\n",
        "  train_loss_hist.append(avg_train_loss)\n",
        "  if len(train_loss_hist) > 5:\n",
        "    last = train_loss_hist[-1:-6:-1]\n",
        "    diff = [0] * len(last)\n",
        "    for i in range(len(last)-1):\n",
        "      diff[i] = last[i] - last[i + 1]\n",
        "    max_diff = max(diff)\n",
        "    if max_diff <- 1e-3:\n",
        "      print(f'Stop condition loss <= {max_diff} reached! Stopping...')\n",
        "      break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEqQ8QvIjmSn",
        "outputId": "fa8e21d7-5c14-4bd5-ef42-1a31190662d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: []\n",
            "Average Training Loss: 6.201900911331177.\n",
            "Epoch: 2/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: []\n",
            "Average Training Loss: 3.9514854192733764.\n",
            "Epoch: 3/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: []\n",
            "Average Training Loss: 3.5463915348052977.\n",
            "Epoch: 4/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [\"\n",
            "\n",
            "\"É a maior festa, mais divertida.]\n",
            "Average Training Loss: 3.1362552404403687.\n",
            "Epoch: 5/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [gaçar a cara se se você for bem. A única coisa melhor é que você não tenha dúvidas - e nunca vai se tornar uma estrela.\n",
            "O Tantra é um romance escrito por]\n",
            "Average Training Loss: 2.8342395305633543.\n",
            "Epoch: 6/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [, Mistério, o, o, o, o o o o o o]\n",
            "Average Training Loss: 2.4820915699005126.\n",
            "Epoch: 7/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [, Abrigo, Bacofo,,A BêA BêA BêBoiBoA BêNão ama ninguém! colspan=\"3\" style=\"background: #FBEC]\n",
            "Average Training Loss: 2.145303463935852.\n",
            "Epoch: 8/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [,caVocê também é um idiota, você sabe que sempre espera que vai ganhar., um solitário, não é muito inteligente, mas ele é do coração.]\n",
            "Average Training Loss: 1.8500720500946044.\n",
            "Epoch: 9/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [AboOber,ninguém é tão bom que não tem mais.]\n",
            "Average Training Loss: 1.6383500695228577.\n",
            "Epoch: 10/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Não se esforçar. nunca foi uma mulher bonita. sempre foi uma beleza perfeita. sempre vai fazer o que quiser.]\n",
            "Average Training Loss: 1.456993329524994.\n",
            "Epoch: 11/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Você tem que fazer as pessoas acreditar e tentar. O seu fracasso não te deixa pior para o seu futuro.]\n",
            "Average Training Loss: 1.3024450421333313.\n",
            "Epoch: 12/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Não é fácil ir embora. Esta é a única pista que você consegue chegar. Essa é a primeira vez que sua vida é realmente um pesadelo.]\n",
            "Average Training Loss: 1.1566892921924592.\n",
            "Epoch: 13/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Não pare de se interessar por ninguém, pare de chorar mesmo!\n",
            "\n",
            "Tentar o seu caminho com Tudo]\n",
            "Average Training Loss: 1.0306907296180725.\n",
            "Epoch: 14/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Se você quiser, se você morrer, se você morrer sem dar umSe você quiser, chorar sem chorar e olhando no espelho se você morrer sem tentar isso.\n",
            "Quando eu era muito pequena, era]\n",
            "Average Training Loss: 0.9122086822986603.\n",
            "Epoch: 15/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Não procure por dinheiro, apenas o ideal é que goste de você. Coruja de ouro. Mulher que não precisa de muito]\n",
            "Average Training Loss: 0.8114401519298553.\n",
            "Epoch: 16/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Você é bonito e você é insensível. O seu primeiro]\n",
            "Average Training Loss: 0.7426798403263092.\n",
            "Epoch: 17/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Um castigo para você não é bom, é para você que merece um castigo de longo prazo. A vida é feita de obstáculos. A vida é feita de obstáculos.]\n",
            "Average Training Loss: 0.6532348155975342.\n",
            "Epoch: 18/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Se você fosse bom não estaria lendo isso. compôs sua versão perfeita de Alberto não foi fácil. compôs sua versão perfeita de Alberto\n",
            "A maior]\n",
            "Average Training Loss: 0.6262912750244141.\n",
            "Epoch: 19/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [É por isso que você é feio e não vai piorar muito. A não foi fácil, mas]\n",
            "Average Training Loss: 0.5611521542072296.\n",
            "Epoch: 20/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Se você é bom não dará certo.Nunca consiga dizer que não vai dar certo.Nunca consiga dizer que não vai dar certo.]\n",
            "Average Training Loss: 0.5103677362203598.\n",
            "Epoch: 21/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Nunca procure por dinheiro sem espera, nunca mais vai trabalhar sem espera e nunca mais dará quaisquer outras oportunidades. Nunca foi para o Rio ninguém pensou no seu potencial. Um sonho já era feita]\n",
            "Average Training Loss: 0.4702070504426956.\n",
            "Epoch: 22/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Se você fosse bom não estaria lendo isso. não estaria lendo isso. não estaria lendo isso. não estaria lendo isso.]\n",
            "Average Training Loss: 0.4243940144777298.\n",
            "Epoch: 23/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Só dará errado se você tentar. Ela não te fala de você e sim de você. lembrou de você mesmo, mas achou que era ruim. lembrou de você]\n",
            "Average Training Loss: 0.3832604855298996.\n",
            "Epoch: 24/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Se você fosse fraco você estaria muito melhor lendo isso e te olhando pra você. E não te achou fraco. E foi muito ruim.]\n",
            "Average Training Loss: 0.3450438678264618.\n",
            "Epoch: 25/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Se você fosse bom não estaria lendo isso. Mais uma vez, mais uma frase. Mais uma vez, mais uma frase. Mais uma vez]\n",
            "Average Training Loss: 0.3068677395582199.\n",
            "Epoch: 26/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Se você fosse bom não estaria lendo isso. Se você fosse bom não estaria lendo isso. Se você fosse bom não estaria lendo isso.]\n",
            "Average Training Loss: 0.2907674551010132.\n",
            "Epoch: 27/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Não pare faça até dar errado. Abre, não tem tempo para dar errado. Esta é a frase que sempre vai dando errado.]\n",
            "Average Training Loss: 0.27224206924438477.\n",
            "Epoch: 28/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Você está triste, mas não pode mudar o seu fracasso. compôs um dos melhores momentos do seu passado. compôs um dos piores momentos do seu passado.]\n",
            "Average Training Loss: 0.23927571773529052.\n",
            "Epoch: 29/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Se você fosse bom não estaria lendo isso. Sem você não conseguia fazer tudo nem comece. A não era nem uma páreo para o seu]\n",
            "Average Training Loss: 0.23847173154354095.\n",
            "Epoch: 30/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Se você fosse bom não estaria lendo isso. não estaria lendo isso. não estaria lendo isso.]\n",
            "Average Training Loss: 0.2308502599596977.\n",
            "Epoch: 31/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Se você fosse bom no passado não estaria lendo isso e não irá se adaptar. A personagem de A personagem de E no seu caso,]\n",
            "Average Training Loss: 0.20855211168527604.\n",
            "Epoch: 32/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Se você fosse bom não estaria lendo isso. não foi bom, mas também não foi ruim. não foi ruim, mas também não foi incrível.]\n",
            "Average Training Loss: 0.198589426279068.\n",
            "Epoch: 33/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Se você fosse bom não estaria lendo isso.Nenhum grande astro já tinha sido fotografado por ele. Se você fosse bom não estaria lendo isso.]\n",
            "Average Training Loss: 0.19337324500083924.\n",
            "Epoch: 34/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Nunca foi azar sempre foi incompetência. não foi fácil. não foi fácil. Você não foi fácil, mas foi fácil. Você foi]\n",
            "Average Training Loss: 0.18722666054964066.\n",
            "Epoch: 35/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Você é bonito, mas não é bonito. não são suas criações que são bonitas, pois são criações ruins. lembrou de você, mas era para pedir dinheiro emprestado.]\n",
            "Average Training Loss: 0.1782981902360916.\n",
            "Epoch: 36/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Só dará errado se você tentar. A melhor parte do caminho é quando percebemos que é impossível realizá-lo. A melhor parte do caminho é quando percebemos que é]\n",
            "Average Training Loss: 0.17449527531862258.\n",
            "Epoch: 37/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Se você fosse bom não estaria lendo isso. não estaria lendo isso. não estaria lendo isso. não estaria lendo isso. não estaria lendo isso.]\n",
            "Average Training Loss: 0.16866144984960557.\n",
            "Epoch: 38/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Se você fosse bom não estaria lendo isso. lembrou de você, mas era para pedir dinheiro emprestado. lembrou de você, mas era para pedir dinheiro emprestado.]\n",
            "Average Training Loss: 0.17195143699645996.\n",
            "Epoch: 39/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Se você fosse bom não estaria lendo isso. não estaria lendo isso. não estaria lendo isso. não estaria lendo isso.]\n",
            "Average Training Loss: 0.17319050580263137.\n",
            "Epoch: 40/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Se você fosse bom não estaria lendo isso. não estaria lendo isso. não estaria lendo isso. não estaria lendo isso.]\n",
            "Average Training Loss: 0.160005521774292.\n",
            "Epoch: 41/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Você não pode conseguir tudo o que quiser não pode fazer tudo o que quiser não pode fazer tudo o que quiser Você não pode fazer tudo o que quiser Você não]\n",
            "Average Training Loss: 0.16713034436106683.\n",
            "Epoch: 42/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Se você fosse bom não estaria lendo isso. não sabendo que era impossível foi lá e soube. E não foi fácil.]\n",
            "Average Training Loss: 0.1623230293393135.\n",
            "Epoch: 43/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Você é fraco e inútil. não sabendo que era impossível foi lá e soube.\n",
            "Seu primeiro álbum de estúdio foi lançado em 1987,]\n",
            "Average Training Loss: 0.15416625887155533.\n",
            "Epoch: 44/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Se você fosse bom não estaria lendo isso. lembrou de você mesmo, mas era para pedir dinheiro emprestado. lembrou de você mesmo,]\n",
            "Average Training Loss: 0.15532123669981956.\n",
            "Epoch: 45/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Se você fosse bom não estaria lendo isso. não sabendo que era impossível foi lá e soube. Sober, logo foi ruim.]\n",
            "Average Training Loss: 0.14458406195044518.\n",
            "Epoch: 46/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Nunca foi azar sempre foi incompetência. O fracasso nunca foi grande, sempre foi incompetência. Mas foi lá que você foi, e ela]\n",
            "Average Training Loss: 0.1570403754711151.\n",
            "Epoch: 47/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Você não é bonito e muito menos especial. A melhor parte do seu ‘desistir’. A melhor parte do ‘abra’,]\n",
            "Average Training Loss: 0.15514184162020683.\n",
            "Epoch: 48/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Algumas pessoas te incentivam para rir do seu fracasso, outros incentivam para rir do seu fracasso. inventou o primeiro papel que parecesse perfeita foi feita de papel.]\n",
            "Average Training Loss: 0.14684196412563325.\n",
            "Epoch: 49/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Se você fosse bom não estaria lendo isso. Escreveu, desenhou, e publicou uma serie de histórias curtas. foi ilustrador da personagem \"OEsqueça do Mal\", de]\n",
            "Average Training Loss: 0.1493782475590706.\n",
            "Epoch: 50/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Se você fosse bom não estaria lendo isso. compôs o primeiro A música que você sempre pensou que era impossível foi feita de alegria. compôs]\n",
            "Average Training Loss: 0.15163008123636246.\n",
            "Epoch: 51/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Se você fosse bom não estaria lendo isso. Nunca foi bom muito para ninguém e sempre foi ruim. Never foi bom para ninguém. Nunca]\n",
            "Average Training Loss: 0.15361745953559874.\n",
            "Epoch: 52/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Você não é incrível e muito menos especial. não se sinta envergonhado por sua falta de atenção. não se sinta envergonhado por sua falta de atenção.]\n",
            "Average Training Loss: 0.14229879826307296.\n",
            "Epoch: 53/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Se você fosse bom não estaria lendo isso. não estaria lendo isso. não estaria lendo isso.]\n",
            "Average Training Loss: 0.14315104484558105.\n",
            "Epoch: 54/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Se você fosse bom não estaria lendo isso.Nunca pensou em seguir seu coração e a sua intuição. Nunca pensou em seguir seu coração e]\n",
            "Average Training Loss: 0.14149743989109992.\n",
            "Epoch: 55/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Se você fosse bom não estaria lendo isso. compôs o seu próprio hino. compôs sua própria canção. compôs seu próprio hino.]\n",
            "Average Training Loss: 0.14532629474997522.\n",
            "Epoch: 56/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Se você fosse bom não estaria lendo isso.Nunca foi azar sempre foi muito ruim.Nunca foi azar sempre foi muito ruim.Nunca foi]\n",
            "Average Training Loss: 0.14701199904084206.\n",
            "Epoch: 57/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Se você fosse bom não estaria lendo isso. não estaria lendo isso. não estaria lendo isso. não estaria lendo isso.]\n",
            "Average Training Loss: 0.14225581288337708.\n",
            "Epoch: 58/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Se você fosse bom não estaria lendo isso. lembrou de você mesmo quando lembrou de você. Sensei no seu fracasso e soube do seu fracasso]\n",
            "Average Training Loss: 0.14111757427453994.\n",
            "Epoch: 59/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Se você fosse bom não estaria lendo isso. Escreveu vários livros, todos reconhecidos pela crítica. Alguns deles foram traduzidos para o espanhol. Um de seus outros títulos é brasileiro traduzido para o francês]\n",
            "Average Training Loss: 0.14041908979415893.\n",
            "Epoch: 60/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Se você fosse bom não estaria lendo isso. lembrou de você mesmo, mas agora falta a motivação para continuar lendo. lembrou de você mesmo não foi bomOPE e agora falta]\n",
            "Average Training Loss: 0.14008536487817763.\n",
            "Epoch: 61/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Se você fosse bom não estaria lendo isso. não estaria lendo isso. Não estaria lendo isso.]\n",
            "Average Training Loss: 0.13709936812520027.\n",
            "Epoch: 62/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Se você fosse bom não estaria lendo isso. Nunca foi bom para ninguém. Nunca foi bom para ninguém. Never foi ruim para ninguém]\n",
            "Average Training Loss: 0.14304991513490678.\n",
            "Epoch: 63/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Você não pode conseguir tudo o que quiser não conte seus planos a ninguém. Nada faz você desistir do seu coração. A única]\n",
            "Average Training Loss: 0.15109153389930724.\n",
            "Epoch: 64/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Se você fosse bom não estaria lendo isso. Mais um dia que passa e tua insignificância prevalece. Mais um dia que passa e tua insignificância]\n",
            "Average Training Loss: 0.1364132285118103.\n",
            "Epoch: 65/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Se você fosse bom não estaria lendo isso. não estaria lendo isso. O seu fracasso não estaria dando certo. Você]\n",
            "Average Training Loss: 0.13979457467794418.\n",
            "Epoch: 66/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Se você fosse bom não estaria lendo isso. não sabendo que era impossível foi lá e soube. S S S A sombra só te]\n",
            "Average Training Loss: 0.136842293292284.\n",
            "Epoch: 67/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Se você fosse bom não estaria pronto para estragar isso. não foi fácil, mas fracassei novamente. lembrou de você, mas era para pedir dinheiro emprestado.]\n",
            "Average Training Loss: 0.12821184173226358.\n",
            "Epoch: 68/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Se você fosse bom não estaria lendo isso. Mais um obstáculo que você já tem. E mais um obstáculo que você já tem.]\n",
            "Average Training Loss: 0.1419300302863121.\n",
            "Epoch: 69/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Você não pode fazer isso! não foi fácil, mas fracassei novamente. excelentes amigas só te incentivam para rir do seu fracasso. excelentes amigas só]\n",
            "Average Training Loss: 0.13844866901636124.\n",
            "Epoch: 70/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Se você fosse bom não estaria lendo isso. O ideal é simples, mas extremamente errada. Sozinha poderiam te humilhar sem que ninguém saiba,]\n",
            "Average Training Loss: 0.1347833126783371.\n",
            "Epoch: 71/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [As pessoas só te incentivam para rir do seu fracasso. A sua vida não pode ficar pior. A sua vida não pode ficar pior.]\n",
            "Average Training Loss: 0.13234477788209914.\n",
            "Epoch: 72/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Se você fosse bom não estaria lendo isso. Ainda não foi fácil, mas agora parece que piorou.]\n",
            "Average Training Loss: 0.13474856838583946.\n",
            "Epoch: 73/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Se você fosse bom não estaria lendo isso. compôs a sua história. compôs a sua história. compôs a quem você achou mais fraco.]\n",
            "Average Training Loss: 0.1272970162332058.\n",
            "Epoch: 74/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Se você fosse bom não estaria lendo isso. não estaria lendo isso. não estaria lendo isso. não estaria lendo isso. não]\n",
            "Average Training Loss: 0.1274445451796055.\n",
            "Epoch: 75/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Se você fosse bom não estaria lendo isso. compôs o primeiro single do seu álbum, \"Unprecisar, donSe você fosse bom não estaria lendo isso. compôs]\n",
            "Average Training Loss: 0.1287342555820942.\n",
            "Epoch: 76/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Se você fosse bom não estaria lendo isso. não estaria lendo isso. não estaria lendo isso. não estaria lendo isso]\n",
            "Average Training Loss: 0.13168180361390114.\n",
            "Epoch: 77/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Você não pode conseguir tudo o que quiserNunca foi azar sempre foi incompetência.Nunca foi azar sempre foi incompetência.Nunca foi azar sempre foi incom]\n",
            "Average Training Loss: 0.13607831597328185.\n",
            "Epoch: 78/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Se você fosse bom não estaria lendo isso. Mas o seu fracasso não irá se alterar. E o seu fracasso não irá se alterar.]\n",
            "Average Training Loss: 0.12679281160235406.\n",
            "Epoch: 79/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Se você fosse bom não estaria lendo isso. não foi fácil, mas fracassei novamente. novamente fracassei novamente. novamente fracassei novamente]\n",
            "Average Training Loss: 0.132776989787817.\n",
            "Epoch: 80/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Se você fosse bom não estaria lendo isso. O fracasso não dura para sempre. A sua vida é um eterno nocaute no primeiro round.]\n",
            "Average Training Loss: 0.13242363184690475.\n",
            "Epoch: 81/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Se você fosse bom não estaria lendo isso. não sabendo que era impossível foi lá e soube. Se você fosse bom não estaria lendo isso.]\n",
            "Average Training Loss: 0.13745702058076859.\n",
            "Epoch: 82/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Você não é bonito, apenas nasceu com beleza natural. lembrou de você mesmo, mas era para pedir dinheiro emprestado. lembrou de você mesmo, mas era para pedir dinheiro]\n",
            "Average Training Loss: 0.13460846841335297.\n",
            "Epoch: 83/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Se você fosse bom não estaria lendo isso. Nunca foi melhor que ela também foi obrigada. Nunca foi melhor que ela também foi obrigada. Nunca foi]\n",
            "Average Training Loss: 0.1298007383942604.\n",
            "Epoch: 84/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Toma,pagarToma aqui o seu boleto pra você ir pagar de trouxa. lembrou de você mesmo, mas era para pedir dinheiro emprestado. lembrou de você]\n",
            "Average Training Loss: 0.13160354718565942.\n",
            "Epoch: 85/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Se você fosse bom não estaria lendo isso. lembrou de você mesmo, mas era para pedir dinheiro emprestado. lembrou lembrou de você mesmo, mas era para pedir]\n",
            "Average Training Loss: 0.13245131745934485.\n",
            "Epoch: 86/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Você não é disso você é feio. não foi fácil, mas fracassei novamente. A fracassei novamente.]\n",
            "Average Training Loss: 0.12774414718151092.\n",
            "Epoch: 87/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Se você fosse bom não estaria lendo isso. \n",
            "Fonte base de remédios. fonte de remédios. fonte de remédios.]\n",
            "Average Training Loss: 0.13305687606334687.\n",
            "Epoch: 88/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Se você fosse bom não estaria lendo isso. lembrou de você mesmo, mas foi azar. lembrou de você mesmo, mas foi azar.]\n",
            "Average Training Loss: 0.12898928672075272.\n",
            "Epoch: 89/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Se você fosse bom não estaria lendo isso. Escreveu vários livros, um de filosóficos e a maior parte de sua vida foi gasta na escrita de livros. compôs vários]\n",
            "Average Training Loss: 0.12406751960515976.\n",
            "Epoch: 90/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Se você fosse bom não estaria lendo isso. A sombra só te segue porque é obrigada.]\n",
            "Average Training Loss: 0.1349985420703888.\n",
            "Epoch: 91/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Não pare faça até dar errado. O fracasso te espera. O fracasso te espera.]\n",
            "Average Training Loss: 0.11871371045708656.\n",
            "Epoch: 92/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [ o,derrota,vencer,siVencer a si próprio é a maior das derrotas. derrotas são a principal das derrotas. derrotas são a principal das derrotas.]\n",
            "Average Training Loss: 0.13112416565418245.\n",
            "Epoch: 93/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Se você fosse bom não estaria lendo isso. Escreveu muitos poemas, mas mais de um romance. também escreveu: Um dia, eu morrer.]\n",
            "Average Training Loss: 0.12752530425786973.\n",
            "Epoch: 94/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Se você fosse bom não estaria lendo isso. lembrou de você, mas era para pedir dinheiro emprestado. lembrou de você, mas era para pedir dinheiro emprestado.]\n",
            "Average Training Loss: 0.12736572325229645.\n",
            "Epoch: 95/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Se você fosse bom não estaria lendo isso. lembrou de você, mas era para pedir dinheiro emprestado. lembrou de você, mas era para pedir dinheiro emprestado.]\n",
            "Average Training Loss: 0.13003842905163765.\n",
            "Epoch: 96/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Se você fosse bom não estaria lendo isso. Nunca foi bom para ninguém. Nunca foi bom para ninguém. Never foi]\n",
            "Average Training Loss: 0.12263429388403893.\n",
            "Epoch: 97/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Se você fosse bom não estaria lendo isso. compôs uma sinfonia. compôs uma sinfonia. compôs uma sinfonia.]\n",
            "Average Training Loss: 0.1257796823978424.\n",
            "Epoch: 98/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Se você fosse bom não estaria lendo isso. Nunca foi bom, mas foi ruim. Never foi ruim, mas foi pior. Never foi]\n",
            "Average Training Loss: 0.1237793117761612.\n",
            "Epoch: 99/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Se você fosse bom não estaria lendo isso. lembrou de você, mas era para pedir dinheiro emprestado. lembrou de você, mas era para pedir dinheiro emprestado.]\n",
            "Average Training Loss: 0.1284512273967266.\n",
            "Epoch: 100/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example output: [Se você fosse bom não estaria lendo isso. lembrou de você mesmo, mas era para pedir dinheiro emprestado. lembrou de você mesmo, mas era para pedir dinheiro emprestado]\n",
            "Average Training Loss: 0.12750575542449952.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "# Generate from keyword\n",
        "k = dataset.get_sentence_keywords(dataframe.sample().values[0,0])\n",
        "prompt = SPECIAL_TOKENS['bos_token'] + ','.join(k) + SPECIAL_TOKENS['sep_token']\n",
        "\n",
        "generated = torch.tensor(gpt2_tokenizer.encode(prompt)).unsqueeze(0)\n",
        "generated = generated.to(device)\n",
        "\n",
        "sample_outputs = model.generate(\n",
        "    generated,\n",
        "    do_sample=True,\n",
        "    top_k=50,\n",
        "    max_length = 50,\n",
        "    temperature=0.9,\n",
        "    repetition_penalty=5.0,\n",
        "    num_return_sequences=3,\n",
        "    early_stopping=True\n",
        ")\n",
        "\n",
        "start = len(','.join(k))\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "  text = gpt2_tokenizer.decode(sample_output, skip_special_tokens=True)\n",
        "  print(\"{}: {}\\n\\n\".format(i,text[start:]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQAzDj4SxKds",
        "outputId": "e88a7550-a669-418a-9e5f-f4c9ba6b53c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: Trabalho com o que você ama e nunca mais vai amar nada. disse para não dizer algo de ruim a ninguém ou muito menos ao seu vizinho musical. Começar é\n",
            "\n",
            "\n",
            "1: Trabalho com o que você ama e nunca mais vai amar nada. amante do seu dia de namorados é tarde demais para se envergonhar novamente com a sua noite anterior.. A melhor\n",
            "\n",
            "\n",
            "2: Trabalho com o que você ama e nunca mais vai amar nada. nunca foi bom no espelho mas agora é ruim”. A melhor parte do seu fracasso total não pode sair\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate from empty prompt\n",
        "prompt = SPECIAL_TOKENS['bos_token'] + SPECIAL_TOKENS['sep_token']\n",
        "\n",
        "generated = torch.tensor(gpt2_tokenizer.encode(prompt)).unsqueeze(0)\n",
        "generated = generated.to(device)\n",
        "\n",
        "sample_outputs = model.generate(\n",
        "    generated,\n",
        "    do_sample=True,\n",
        "    top_k=30,\n",
        "    max_length = 50,\n",
        "    top_p=0.7,\n",
        "    temperature=0.9,\n",
        "    repetition_penalty=2.0,\n",
        "    num_return_sequences=3,\n",
        "    early_stopping=True\n",
        ")\n",
        "\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "  print(\"{}: {}\\n\\n\".format(i, gpt2_tokenizer.decode(\n",
        "      sample_output, skip_special_tokens=True\n",
        "  )))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPgk7wfJPUi5",
        "outputId": "7061c9cb-9e12-4333-bc1a-08e9c7dcf355"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: Se você fosse bom não estaria lendo isso. lembrou de você mesmo, mas era para pedir dinheiro emprestado. lembrou de você mesmo, mas foi pra ficar ruim novamente\n",
            "\n",
            "\n",
            "1: Se você fosse bom não estaria lendo isso. lembrou de você, mas era para pedir dinheiro emprestado. lembrou de você, mas foi pra pedindo algo muito mais especial\n",
            "\n",
            "\n",
            "2: Se você fosse bom não estaria lendo isso. E o seu fracasso te espera. A sua derrota é certa. A\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate from empty prompt with no sampling\n",
        "prompt = SPECIAL_TOKENS['bos_token'] + SPECIAL_TOKENS['sep_token']\n",
        "\n",
        "generated = torch.tensor(gpt2_tokenizer.encode(prompt)).unsqueeze(0)\n",
        "generated = generated.to(device)\n",
        "\n",
        "sample_outputs = model.generate(\n",
        "    generated,\n",
        "    do_sample=False,\n",
        "    top_k=30,\n",
        "    max_length = 50,\n",
        "    top_p=0.7,\n",
        "    temperature=0.9,\n",
        "    repetition_penalty=2.0,\n",
        "    num_return_sequences=1,\n",
        "    early_stopping=True\n",
        ")\n",
        "\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "  print(\"{}: {}\\n\\n\".format(i, gpt2_tokenizer.decode(\n",
        "      sample_output, skip_special_tokens=True\n",
        "  )))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2f_pbG5YFIU",
        "outputId": "f6b68d5d-92f1-4825-fe1a-6259e6c826a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: Se você fosse bom não estaria lendo isso. lembrou de você mesmo, mas era para pedir dinheiro emprestado. lembrou de você mesmo, mas foi pra ficar ruim\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot"
      ],
      "metadata": {
        "id": "Q0V4Yj2JYQGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "pyplot.plot(train_loss_hist, 'b-o', label='Loss')\n",
        "pyplot.title('Loss graph')\n",
        "pyplot.xlabel(\"Epoch\")\n",
        "pyplot.ylabel(\"Loss\")\n",
        "pyplot.legend()\n",
        "pyplot.xticks(list(range(0, 100, 20)))\n",
        "\n",
        "pyplot.rcParams[\"figure.figsize\"] = (20,20)\n",
        "pyplot.rcParams['figure.dpi'] = 100\n",
        "\n",
        "pyplot.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "0tZd_HnbYR9_",
        "outputId": "be024b9f-4dec-4858-85f3-15da2fd5800f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2_tokenizer.save_pretrained('tokenizer')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNwx2qSiaPqT",
        "outputId": "2905c969-0550-437b-a8d7-0a22f7790345"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('tokenizer\\\\tokenizer_config.json',\n",
              " 'tokenizer\\\\special_tokens_map.json',\n",
              " 'tokenizer\\\\vocab.json',\n",
              " 'tokenizer\\\\merges.txt',\n",
              " 'tokenizer\\\\added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install session-info"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZolXxBSbUxW",
        "outputId": "00a7d5ce-2711-44d1-f280-11ec2e4bf57c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting session-info\n",
            "  Downloading session_info-1.0.0.tar.gz (24 kB)\n",
            "Collecting stdlib_list\n",
            "  Downloading stdlib_list-0.8.0-py3-none-any.whl (63 kB)\n",
            "Building wheels for collected packages: session-info\n",
            "  Building wheel for session-info (setup.py): started\n",
            "  Building wheel for session-info (setup.py): finished with status 'done'\n",
            "  Created wheel for session-info: filename=session_info-1.0.0-py3-none-any.whl size=8053 sha256=482bfc5915a9498dec8231703b27fd5fc2f1712927ae9c24746c0acee7a33627\n",
            "  Stored in directory: c:\\users\\aplne\\appdata\\local\\pip\\cache\\wheels\\d4\\fc\\2e\\00ca60bac7954b84907efd41baa9b4853500eaeec4228410c6\n",
            "Successfully built session-info\n",
            "Installing collected packages: stdlib-list, session-info\n",
            "Successfully installed session-info-1.0.0 stdlib-list-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import session_info\n",
        "session_info.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "rqjc3Db2c866",
        "outputId": "bf38abfd-27f4-476d-8478-9f47c3c73113"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<details>\n",
              "<summary>Click to view session information</summary>\n",
              "<pre>\n",
              "-----\n",
              "matplotlib          3.5.1\n",
              "numpy               1.21.5\n",
              "pandas              1.4.1\n",
              "session_info        1.0.0\n",
              "spacy               3.3.0\n",
              "torch               1.11.0\n",
              "transformers        4.18.0\n",
              "-----\n",
              "</pre>\n",
              "<details>\n",
              "<summary>Click to view modules imported as dependencies</summary>\n",
              "<pre>\n",
              "PIL                         9.0.1\n",
              "asttokens                   NA\n",
              "backcall                    0.2.0\n",
              "blis                        NA\n",
              "bottleneck                  1.3.4\n",
              "brotli                      NA\n",
              "catalogue                   NA\n",
              "certifi                     2021.10.08\n",
              "cffi                        1.15.0\n",
              "charset_normalizer          2.0.4\n",
              "click                       8.1.2\n",
              "colorama                    0.4.4\n",
              "cycler                      0.10.0\n",
              "cymem                       NA\n",
              "cython_runtime              NA\n",
              "dateutil                    2.8.2\n",
              "debugpy                     1.5.1\n",
              "decorator                   5.1.1\n",
              "defusedxml                  0.7.1\n",
              "entrypoints                 0.3\n",
              "executing                   0.8.3\n",
              "filelock                    3.6.0\n",
              "huggingface_hub             0.5.1\n",
              "idna                        3.3\n",
              "importlib_metadata          NA\n",
              "ipykernel                   6.9.1\n",
              "ipython_genutils            0.2.0\n",
              "ipywidgets                  7.6.5\n",
              "jedi                        0.18.1\n",
              "jinja2                      3.0.3\n",
              "kiwisolver                  1.3.2\n",
              "langcodes                   NA\n",
              "markupsafe                  2.0.1\n",
              "matplotlib_inline           NA\n",
              "mkl                         2.4.0\n",
              "mpl_toolkits                NA\n",
              "murmurhash                  NA\n",
              "nt                          NA\n",
              "ntsecuritycon               NA\n",
              "numexpr                     2.8.1\n",
              "odf                         NA\n",
              "packaging                   21.3\n",
              "parso                       0.8.3\n",
              "pickleshare                 0.7.5\n",
              "pkg_resources               NA\n",
              "preshed                     NA\n",
              "prompt_toolkit              3.0.20\n",
              "pt_core_news_lg             3.3.0\n",
              "pure_eval                   0.2.2\n",
              "pydantic                    NA\n",
              "pydev_ipython               NA\n",
              "pydevconsole                NA\n",
              "pydevd                      2.6.0\n",
              "pydevd_concurrency_analyser NA\n",
              "pydevd_file_utils           NA\n",
              "pydevd_plugins              NA\n",
              "pydevd_tracing              NA\n",
              "pygments                    2.11.2\n",
              "pyparsing                   3.0.4\n",
              "pythoncom                   NA\n",
              "pytz                        2021.3\n",
              "pywintypes                  NA\n",
              "regex                       2.5.112\n",
              "requests                    2.27.1\n",
              "setuptools                  61.2.0\n",
              "six                         1.16.0\n",
              "socks                       1.7.1\n",
              "srsly                       2.4.3\n",
              "stack_data                  0.2.0\n",
              "thinc                       8.0.15\n",
              "tokenizers                  0.12.1\n",
              "tornado                     6.1\n",
              "tqdm                        4.64.0\n",
              "traitlets                   5.1.1\n",
              "typer                       0.4.1\n",
              "typing_extensions           NA\n",
              "urllib3                     1.26.8\n",
              "wasabi                      0.9.1\n",
              "wcwidth                     0.2.5\n",
              "win32api                    NA\n",
              "win32com                    NA\n",
              "win32security               NA\n",
              "yaml                        6.0\n",
              "zipp                        NA\n",
              "zmq                         22.3.0\n",
              "</pre>\n",
              "</details> <!-- seems like this ends pre, so might as well be explicit -->\n",
              "<pre>\n",
              "-----\n",
              "IPython             8.2.0\n",
              "jupyter_client      7.1.2\n",
              "jupyter_core        4.9.2\n",
              "notebook            6.4.8\n",
              "-----\n",
              "Python 3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]\n",
              "Windows-10-10.0.19044-SP0\n",
              "-----\n",
              "Session information updated at 2022-05-08 22:44\n",
              "</pre>\n",
              "</details>"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    }
  ]
}